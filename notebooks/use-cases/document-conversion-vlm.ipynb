{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c83150f-fa8b-42a1-8974-ce9483912fba",
   "metadata": {},
   "source": [
    "# Data Processing: Document Conversion with VLM Docling\n",
    "\n",
    "This notebook uses **vision‚Äëlanguage model (VLM)** powered [Docling](https://docling-project.github.io/docling/) to convert PDF documents into Markdown and the [Docling Document](https://docling-project.github.io/docling/concepts/docling_document/) format, a structured representation of the original document that can be exported as JSON.\n",
    "\n",
    "VLM conversion leverages multimodal models to interpret complex layouts, figures, and image‚Äëonly pages. It is especially helpful when standard (non‚ÄëVLM) or OCR pipelines miss content embedded in charts, diagrams, screenshots, hand-written notes, or dense tables.\n",
    "\n",
    "You can run VLM in two ways:\n",
    "\n",
    "- **Remote VLM service**: route processing through a VLM [model service](https://github.com/rh-aiservices-bu/models-aas) API by providing an endpoint URL, model name, and API key.\n",
    "- **Local VLM**: run a lightweight model locally.\n",
    "\n",
    "This notebook walks you through configuration and conversion and produces both Markdown and Docling JSON outputs for each input PDF."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58fb60e",
   "metadata": {},
   "source": [
    "## üì¶ Installation\n",
    "\n",
    "Install the [Docling](https://docling-project.github.io/docling/) package into this notebook environment. Run this once per session, it may take a minute. If you restart the kernel or change runtimes, re-run this cell before continuing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf4340c-cfd4-418c-955b-be8c0d544e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -qq docling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1bfac7a",
   "metadata": {},
   "source": [
    "## ‚ö†Ô∏è Important Notes\n",
    "\n",
    "**Exception Handling**: This notebook demonstrates the core workflow with minimal error handling for clarity. When using your own data or deploying to production:\n",
    "\n",
    "- Add try-except blocks around file I/O operations\n",
    "- Handle network errors for URL-based document loading\n",
    "- Validate document formats and sizes before processing\n",
    "- Implement timeouts for long-running operations\n",
    "- Add proper logging for debugging and monitoring\n",
    "- Handle cases where documents fail to convert or chunk\n",
    "\n",
    "Example of adding exception handling:\n",
    "```python\n",
    "try:\n",
    "    result = converter.convert(file_path)\n",
    "    document = result.document\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to convert {file_path}: {str(e)}\")\n",
    "    continue  # Skip to next document\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f5e2659-e626-4235-97fc-f311adf8f5b7",
   "metadata": {},
   "source": [
    "## üîß Configuration\n",
    "\n",
    "### Set files to convert\n",
    "\n",
    "Set the list of PDF files to convert. You can mix public web URLs and local file paths, each entry will be processed in order. Replace the example with your own documents as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d12166-8b40-4c46-9147-27cfc1c8b09a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "files = [\n",
    "    \"https://raw.githubusercontent.com/py-pdf/sample-files/refs/heads/main/001-trivial/minimal-document.pdf\",\n",
    "    \"https://raw.githubusercontent.com/py-pdf/sample-files/refs/heads/main/003-pdflatex-image/pdflatex-image.pdf\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fa56da",
   "metadata": {},
   "source": [
    "### Set output directory\n",
    "\n",
    "Choose where to save results. This notebook creates the folder if it doesn‚Äôt exist and writes one `json` ([Docling Document](https://docling-project.github.io/docling/concepts/docling_document/)) and one `md` file per source file, using the source‚Äôs base name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46dd4e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "output_dir_name = \"document-conversion-vlm/output\"\n",
    "\n",
    "output_dir = Path(output_dir_name)\n",
    "output_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89396e34",
   "metadata": {},
   "source": [
    "### Choose a VLM backend\n",
    "\n",
    "Select how the VLM will run:\n",
    "\n",
    "- Set `remote = True` to use a hosted VLM endpoint (configure URL, model name, and API key).\n",
    "- Set `remote = False` to use the local and lightweight smolDocling model.\n",
    "\n",
    "If you‚Äôre unsure, start with the local option to test the results. Depending on your hardware resources and the characteristics of your documents, VLM models can take a significant amount of time to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "621f644c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set to True to use a VLM model hosted on a remote server\n",
    "remote = False\n",
    "\n",
    "# If remote = True, set the remote model endpoint URL (can be overridden via VLM_SERVICE_ENDPOINT_URL)\n",
    "remote_model_endpoint_url = os.getenv(\"VLM_SERVICE_ENDPOINT_URL\", \"https://path.to.your.vlm.endpoint/v1/chat/completions\")\n",
    "\n",
    "# If remote = True, set the remote model name (can be overridden via VLM_SERVICE_MODEL_NAME)\n",
    "remote_model_name = os.getenv(\"VLM_SERVICE_MODEL_NAME\", \"granite-vision-3-2\")\n",
    "\n",
    "# If remote = True, set the remote model API key (can be overridden via VLM_SERVICE_API_KEY)\n",
    "remote_model_api_key = os.getenv(\"VLM_SERVICE_API_KEY\", \"your.api.key.here\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d4e3ef-2fdb-45a3-a217-b07638a35363",
   "metadata": {},
   "source": [
    "### Configure the VLM conversion pipeline\n",
    "\n",
    "Next we create the configuration options for the conversion pipelines supported by this notebook.\n",
    "\n",
    "For additional customization and a complete reference of Docling's conversion pipeline configuration, check the [official documentation](https://docling-project.github.io/docling/) and [examples](https://docling-project.github.io/docling/examples/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be47eb2-8e2d-445c-a5de-fcdd17ef7097",
   "metadata": {},
   "outputs": [],
   "source": [
    "from docling.datamodel.accelerator_options import AcceleratorDevice, AcceleratorOptions\n",
    "from docling.document_converter import DocumentConverter, PdfFormatOption\n",
    "from docling.datamodel.base_models import InputFormat\n",
    "from docling.datamodel.pipeline_options import (\n",
    "    VlmPipelineOptions,\n",
    "    smoldocling_vlm_conversion_options,\n",
    ")\n",
    "from docling.datamodel.pipeline_options_vlm_model import ApiVlmOptions, ResponseFormat\n",
    "\n",
    "pipeline_options = VlmPipelineOptions()\n",
    "pipeline_options.generate_picture_images = True\n",
    "pipeline_options.document_timeout = 600\n",
    "\n",
    "if remote:\n",
    "    pipeline_options.enable_remote_services = True\n",
    "    pipeline_options.vlm_options = ApiVlmOptions(\n",
    "        url=remote_model_endpoint_url,\n",
    "        params=dict(\n",
    "            model_id=remote_model_name,\n",
    "            parameters=dict(\n",
    "                max_new_tokens=400,\n",
    "            ),\n",
    "        ),\n",
    "        prompt=\"Convert the full page to markdown. Do not miss any text.\",\n",
    "        timeout=600,\n",
    "        response_format=ResponseFormat.MARKDOWN,\n",
    "        headers={\n",
    "            \"Authorization\": f\"Bearer {remote_model_api_key}\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "else:\n",
    "    pipeline_options.vlm_options = smoldocling_vlm_conversion_options\n",
    "    pipeline_options.accelerator_options = AcceleratorOptions(\n",
    "        num_threads=4, device=AcceleratorDevice.AUTO\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b286e6f2",
   "metadata": {},
   "source": [
    "### Configure enrichments\n",
    "\n",
    "Depending on your documents, you may benefit from optional enrichments. These add specialized processing for specific content types and can increase processing time.\n",
    "\n",
    "- `do_picture_description`: Generates captions for pictures with a vision model.\n",
    "- `do_picture_classification`: Classifies pictures (e.g., charts, flow diagrams, logos, signatures).\n",
    "\n",
    "All enrichments are disabled by default; enable the ones you need below. See the [enrichments docs](https://docling-project.github.io/docling/usage/enrichments/) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5bf3df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets picture description and classification\n",
    "pipeline_options.do_picture_description = False\n",
    "pipeline_options.do_picture_classification = False\n",
    "\n",
    "# If you enable enrichments, you may benefit from increasing the image scale (e.g. to 2)\n",
    "pipeline_options.images_scale = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab035e-e05e-41e8-be90-23527b5d4bc4",
   "metadata": {},
   "source": [
    "## ‚ú® Conversion\n",
    "\n",
    "Finally, use the pipeline options we configured to convert every document into one `json` ([Docling Document](https://docling-project.github.io/docling/concepts/docling_document/)) and one `md` (markdown), which will be stored in the output directory configured earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a45e16-8fa0-4223-9890-7d75f6869aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from docling_core.types.doc import ImageRefMode\n",
    "from docling.pipeline.vlm_pipeline import VlmPipeline\n",
    "\n",
    "# Create the document converter\n",
    "converter = DocumentConverter(\n",
    "    format_options={\n",
    "        InputFormat.PDF: PdfFormatOption(\n",
    "            pipeline_options=pipeline_options,\n",
    "            pipeline_cls=VlmPipeline,\n",
    "        )\n",
    "    }\n",
    ")\n",
    "\n",
    "if not files:\n",
    "    raise ValueError(\"No input files specified. Please set the 'files' list above.\")\n",
    "\n",
    "for file in files:\n",
    "    # Convert the file\n",
    "    print(f\"Converting {file}...\")\n",
    "\n",
    "    result = converter.convert(file)\n",
    "    document = result.document\n",
    "    dictionary = document.export_to_dict()\n",
    "\n",
    "    file_path = Path(file)\n",
    "\n",
    "    # Export the document to JSON\n",
    "    json_output_path = (output_dir / f\"{file_path.stem}.json\")\n",
    "    with open(json_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(dictionary, f)\n",
    "        print(f\"‚úì Path of JSON output is: {json_output_path.resolve()}\")\n",
    "\n",
    "    # Export the document to Markdown\n",
    "    md_output_path = output_dir / f\"{file_path.stem}.md\"\n",
    "    with open(md_output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        markdown = document.export_to_markdown(image_mode=ImageRefMode.EMBEDDED)\n",
    "        f.write(markdown)\n",
    "        print(f\"‚úì Path of markdown output is: {md_output_path.resolve()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56dc2c21",
   "metadata": {},
   "source": [
    "## üç© Additional resources\n",
    "\n",
    "For additional example notebooks related to Data Processing, check the [Open Data Hub Data Processing](https://github.com/opendatahub-io/odh-data-processing/) repository on GitHub.\n",
    "\n",
    "### Any Feedback?\n",
    "\n",
    "We'd love to hear if you have any feedback on this or any other notebook in this series! Please [open an issue](https://github.com/opendatahub-io/odh-data-processing/issues) and help us improve our demos."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
